{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "# # saving high quality figures\n",
        "# matplotlib.use('agg')\n",
        "# from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from functools import reduce\n",
        "%pip install -U --quiet 'gym==0.21.0' 'gym[atari,accept-rom-license]'\n",
        "import gym\n",
        "from gym import spaces\n",
        "from wrappers import *"
      ],
      "metadata": {
        "id": "oQrFRDZ0ZKYH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NET(nn.Module):\n",
        "    # define the networ structure\n",
        "    def __init__(self,\n",
        "                 observation_space: spaces.Box,\n",
        "                 action_space: spaces.Discrete):\n",
        "        super().__init__()\n",
        "        assert type(\n",
        "            observation_space) == spaces.Box, 'observation_space must be of type Box'\n",
        "        assert len(\n",
        "            observation_space.shape) == 3, 'observation space must have the form channels x width x height'\n",
        "        assert type(\n",
        "            action_space) == spaces.Discrete, 'action_space must be of type Discrete'\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=observation_space.shape[0], out_channels=32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=4, stride=2),\n",
        "            nn.ReLU()\n",
        "            )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_features=32*9*9+1 , out_features=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, s, a):\n",
        "\n",
        "        #convert s from Lazyframe to tensor\n",
        "        state_stack = np.array(s)\n",
        "        #normlize\n",
        "        state_stack_norm = np.array(state_stack) / 255.0\n",
        "        state_stack_norm = torch.from_numpy(state_stack_norm).float().unsqueeze(0)\n",
        "        conv_out = self.conv(state_stack_norm).view(state_stack_norm.size()[0],-1)\n",
        "        a = torch.tensor(a, dtype=torch.float).reshape((1,1))\n",
        "        x = torch.cat((conv_out, a), 1)\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "class ZapNN():\n",
        "\n",
        "    eps = 1e-4              # epsilon used in computing matrix gain G_n\n",
        "    beta = 1\n",
        "    gamma = 0.85            # parameter for the second time scale (corresponds to \\rho in the paper)\n",
        "    eps_greedy = 0.1        # epsilon for the epsilon-greedy policy\n",
        "    \n",
        "    def __init__(self, env):\n",
        "        '''Initalize Zap Q-learning agent.'''\n",
        "        self.net = NET(env.observation_space,env.action_space) \n",
        "        self.zeta = NET(env.observation_space,env.action_space) # delayed Q-function for computing the eligibility vector\n",
        "        self.zeta.load_state_dict(self.net.state_dict())\n",
        "        self.action_n = env.action_space.n\n",
        "        self.size = sum(p.numel() for p in self.net.parameters())\n",
        "        print(\"Number of model parameters\", self.size)\n",
        "        assert self.size == sum(p.numel() for p in self.net.parameters() if p.requires_grad), \"The parameters are not all trainable, check!!! \"\n",
        "        self.Ahat = torch.eye(self.size, requires_grad = False)\n",
        "        self.A, self.barf = torch.zeros(self.size, self.size, requires_grad = False), torch.zeros(self.size, requires_grad = False)\n",
        "        self.iter_nums = [0, 0]\n",
        "        self.ratio, self.lr = 100, 0.005                             # constant step size\n",
        "        self.block = 50\n",
        "        return\n",
        "\n",
        "    def sarsa(self, state, ptype = 'eps'):\n",
        "        '''Epsilon greedy policy.'''\n",
        "        if ptype == 'eps':\n",
        "            if np.random.rand() < self.eps_greedy:\n",
        "                return np.random.randint(2)\n",
        "            return self.greedy_act(state)\n",
        "        else:\n",
        "            raise NameError('Sarsa type not properly defied yet')\n",
        "    \n",
        "    def decide(self, state, strategy):\n",
        "        '''Behavior policy.'''\n",
        "        if strategy == 'greedy':\n",
        "            return self.greedy_act(state)\n",
        "        elif strategy == 'sarsa':\n",
        "            return self.sarsa(state, 'eps')\n",
        "        else:\n",
        "            raise NameError('Running policy has not been defined yet.')\n",
        "\n",
        "    def greedy_act(self, nstate):\n",
        "        '''select the greedy action based on the current value function. This is used for Q-learning update'''\n",
        "        with torch.no_grad():\n",
        "            qs = [self.net(nstate, naction) for naction in range(self.action_n)]\n",
        "            return np.argmax(qs)\n",
        "\n",
        "    def gradient(self, outputs, inputs, retain_graph=None, create_graph=False):\n",
        "        grads = torch.autograd.grad(outputs, inputs,\n",
        "                                allow_unused=True,\n",
        "                                retain_graph=retain_graph,\n",
        "                                create_graph=create_graph)\n",
        "        grads = [x if x is not None else torch.zeros_like(y) for x, y in zip(grads, inputs)]\n",
        "        return torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "\n",
        "    def grad_td(self, state, action, state_next, greedy_act, reward, params, done):\n",
        "        '''\n",
        "        Compute the gradient of temporal difference error d_{n+1}.\n",
        "        '''\n",
        "        self.net.zero_grad()\n",
        "        output = reward +  (not done) * self.beta * self.net(state_next, greedy_act) - self.net(state, action)\n",
        "        grads = torch.autograd.grad(output, params)\n",
        "        grads = torch.cat([x.contiguous().view(-1) for x in grads])\n",
        "        return grads.detach(), output.item()\n",
        "\n",
        "        \n",
        "    def zap_jacob(self, state, action, state_next, reward, done):\n",
        "        '''\n",
        "        Compute the jacobian matrix A_n(\\theta_n) = f(\\theta_n, \\Phi_{n+1}) with zeta being delayed.\n",
        "        '''\n",
        "        greedy_act = self.greedy_act(state_next)\n",
        "        params = list(self.net.parameters())\n",
        "        gd, d = self.grad_td(state, action, state_next, greedy_act, reward, params, done)\n",
        "        self.zeta.zero_grad()\n",
        "        zeta = self.gradient(self.zeta(state, action), list(self.zeta.parameters()))\n",
        "        return torch.ger(zeta, gd), d*zeta.detach()\n",
        "    \n",
        "    def learn(self, state, action, reward, state_next, episode, done, ):\n",
        "        ''' \n",
        "        Accumulate the one-step SA update within a block.\n",
        "        '''\n",
        "        A, sa_update= self.zap_jacob(state, action, state_next, reward, done)\n",
        "        self.barf +=  1.0/((self.iter_nums[1] % self.block) + 1.0)*(sa_update - self.barf)  # RAM consuming\n",
        "        self.A +=  1.0/((self.iter_nums[1] % self.block) + 1.0)*(A  - self.A) # RAM consuming \n",
        "        if (self.iter_nums[1] + 1) % self.block == 0:\n",
        "            # update the parameters of neural network\n",
        "            self.update(self.iter_nums[1] // self.block, episode, 'ds', 100.0)\n",
        "        self.iter_nums[1] += 1\n",
        "        return\n",
        "\n",
        "    def update(self, block_n, episode, stepsize = 'ds', offset = 1.0):\n",
        "        '''\n",
        "        Update the parameters of \\haA_n, \\theta_n by Zap SA algorithm using accumulated SA updates averages over the last block.\n",
        "        '''\n",
        "        if stepsize == 'ds':\n",
        "            # decreasing step-size\n",
        "            fast_step = 1.0 - reduce(lambda x, y: x*y, [1.0 - 1.0/math.pow(j + offset, self.gamma) for j in range(self.iter_nums[0], self.iter_nums[1]+1)])\n",
        "            self.Ahat += fast_step * (self.A - self.Ahat)\n",
        "            td = - 1.0/(block_n + offset) *torch.solve(torch.mv(self.Ahat.t(), self.barf).view(-1, 1), self.eps*torch.eye(self.size) + torch.mm(self.Ahat.t(), self.Ahat))[0].view(-1)\n",
        "            self.iter_nums[0] = self.iter_nums[1] + 1\n",
        "        elif stepsize == 'cs':\n",
        "            # constant step-size\n",
        "            self.Ahat +=  self.ratio * self.lr * (self.A - self.Ahat)\n",
        "            td = - self.lr *torch.solve(torch.mv(self.Ahat.t(), self.barf).view(-1, 1), self.eps*torch.eye(self.size) + torch.mm(self.Ahat.t(), self.Ahat))[0].view(-1)\n",
        "        else:\n",
        "            raise NameError('Step size for Zap not recognized.')\n",
        "\n",
        "        ## update the parameters of neural net\n",
        "        self._add_grad(td.view(-1), self.net.parameters())\n",
        "        \n",
        "        ## clear the temporary gains and barfs accumulated\n",
        "        self.A.zero_(), self.barf.zero_()\n",
        "\n",
        "        if (block_n + 1) % 20 == 0:\n",
        "            # update the function for computing eligibility vector.\n",
        "            self.zeta.load_state_dict(self.net.state_dict())\n",
        "\n",
        "        return\n",
        "\n",
        "    def _add_grad(self, td, params):\n",
        "        ''' Adding the update to the parameters of the network.'''\n",
        "        offset = 0\n",
        "        for p in params:\n",
        "            numel = p.numel()\n",
        "            # use p.data such that this operation won't be traced to compute gradients.\n",
        "            p.data.add_(td[offset:offset + numel].view_as(p.data))\n",
        "            offset += numel\n",
        "        assert offset == self.size, \"dimension of gradient is different than dimension of parameters.\" \n",
        "        return\n",
        "\n",
        "def terminal(env):\n",
        "    ''' determine if the state of system reaches the termination state. The code is based on source code of Cartpole from OpenAI gym.'''\n",
        "    x, theta = env.state[0], env.state[2]\n",
        "    done =  x < -env.x_threshold \\\n",
        "                or x > env.x_threshold \\\n",
        "                or theta < -env.theta_threshold_radians \\\n",
        "                or theta > env.theta_threshold_radians\n",
        "    return done\n",
        "\n",
        "def play_zap(env, agent, episode, strategy = 'sarsa', train=False, render=True):\n",
        "    ''' Run Zap algorithm over one episode. '''\n",
        "    episode_reward = 0\n",
        "    observation = env.reset()\n",
        "    action = agent.decide(observation, strategy)\n",
        "    while True:\n",
        "        if render:\n",
        "            env.render()\n",
        "        observation_next, reward, done, _ = env.step(action)\n",
        "        episode_reward += reward\n",
        "        real_done = done\n",
        "        action_next = agent.decide(observation_next, strategy) \n",
        "        if train:\n",
        "            agent.learn(observation, action, reward, observation_next, episode, real_done)\n",
        "        # print(\"I don't think it can run this far 2\")\n",
        "        observation, action = observation_next, action_next\n",
        "        if done:\n",
        "            break\n",
        "    if train and real_done:\n",
        "        ## real done, instead of just hitting the maximum number of steps\n",
        "        agent.learn(observation, action, 0, observation_next,episode, real_done)\n",
        "    return episode_reward, real_done\n",
        "\n",
        "def test_zap(env, agent, render=True):\n",
        "    ''' Run simulation following the greedy policy phi^\\theta induced by Q^\\theta.'''\n",
        "    episode_reward = 0\n",
        "    observation = env.reset()\n",
        "    action = agent.decide(observation, 'greedy')\n",
        "    while True:\n",
        "        if render:\n",
        "            env.render()\n",
        "        observation_next, reward, done, _ = env.step(action)\n",
        "        episode_reward += reward\n",
        "        action_next = agent.decide(observation_next, 'greedy') \n",
        "        observation, action = observation_next, action_next\n",
        "        if done:\n",
        "            break\n",
        "    return episode_reward, done\n",
        "\n",
        "\n",
        "def OneRun(env, args, exp_indx, render, episodes = 10000):\n",
        "    '''\n",
        "    Run one simulation for training Zap.\n",
        "    '''\n",
        "    seed = exp_indx\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    env.seed(seed)\n",
        "    env.reset()\n",
        "    agent = ZapNN(env)\n",
        "    policy_rewards = []\n",
        "    env._max_episode_steps = 1000 ## maximum time step for each episode.\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        episode_reward, done = play_zap(env, agent, episode, 'sarsa', train=True, render = False)\n",
        "        \n",
        "        if (episode + 1)% 200 == 0:\n",
        "            ## evaluate the greedy policy phi^\\theta induced by Q^\\theta.\n",
        "            print('Playing episodes: {}...ended with steps {}'.format(episode, episode_reward))\n",
        "            perf_eval = 0.0\n",
        "            for i in range(100):\n",
        "                reward, _ = test_zap(env, agent, render)\n",
        "                perf_eval += 1.0/(i + 1.0)*(reward - perf_eval)\n",
        "            print('Start testing!... ' + str(perf_eval))\n",
        "            policy_rewards.append(perf_eval)\n",
        "    return policy_rewards\n",
        "\n",
        "def env_wrapper(game, frame_skip_length=4, stack_length=4):\n",
        "    # create and update the environment\n",
        "    env = gym.make(game)\n",
        "    env = NoopResetEnv(env, noop_max=30)\n",
        "    # original observation space 210 * 160 return max_frame in the _obs_buffer with frame skip 4\n",
        "    env = MaxAndSkipEnv(env, skip=frame_skip_length)\n",
        "    # calculate lives and return true done for specific game\n",
        "    env = EpisodicLifeEnv(env)\n",
        "    env = FireResetEnv(env)\n",
        "    # important add function for warp frame to 84*84*1\n",
        "    env = WarpFrame(env)\n",
        "    # print(env.observation_space.shape)\n",
        "    # normlize and change to 1*84*84 shape\n",
        "    env = PyTorchFrame(env)\n",
        "    # print(env.observation_space.shape)\n",
        "    # add reward function to clip reward to -1,0,1\n",
        "    env = ClipRewardEnv(env)\n",
        "    # print(env.observation_space.shape)\n",
        "    # action = 0\n",
        "    # ob, reward, done, info = env.step(action)\n",
        "    # print(ob.shape)\n",
        "    env = FrameStack(env, stack_length)\n",
        "    # env = gym.wrappers.Monitor(env, './video/', video_callable=lambda episode_id: episode_id % 100 == 0, force=True)\n",
        "    return env"
      ],
      "metadata": {
        "id": "OD7c_GmVZdbZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    episodes = 10000   # overall number of trainning episodes.\n",
        "    N_SET = 3\n",
        "    RewardList = np.empty((int(episodes/200), N_SET))\n",
        "    env = env_wrapper('BreakoutNoFrameskip-v4')\n",
        "    render = False\n",
        "    result_dir = 'result_dir'\n",
        "    if not os.path.exists(result_dir):\n",
        "        os.mkdir('result_dir')\n",
        "\n",
        "    for i in range(N_SET):\n",
        "        rewardOfThisRun = OneRun(env, result_dir, i, render, episodes)\n",
        "        RewardList[:,i] = rewardOfThisRun\n",
        "    env.close()"
      ],
      "metadata": {
        "id": "MDM7i-tyOqDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(range((int(episodes/200))), np.mean(RewardList, axis=1))\n",
        "plt.xlabel('Set number (smoothed over every {} epochs)'.format(200))\n",
        "plt.ylabel('Average eposide reward')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "uXAQ7YEginpP",
        "outputId": "6f478d02-a8e8-453e-9067-5ee13cb6d57c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Average eposide reward')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}